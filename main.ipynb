{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70d33c7-e993-42fd-9755-b478fe56fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.quantization\n",
    "\n",
    "# Set device (use CUDA if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MNIST dataset with normalization\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59e9d61-85e1-40f5-b38b-eef2597cfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "# Define the transformation to normalize MNIST data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST training dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Load MNIST testing dataset\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Combine datasets\n",
    "combined_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "import random\n",
    "\n",
    "def split_dataset(combined_dataset, N):\n",
    "    # Total number of samples in the dataset\n",
    "    M = len(combined_dataset)\n",
    "    indices = list(range(M))\n",
    "    split_size = M // N\n",
    "    \n",
    "    # Shuffle indices to ensure randomness in splitting\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Split indices into N parts\n",
    "    user_data = [indices[i * split_size:(i + 1) * split_size] for i in range(N)]\n",
    "    \n",
    "    # Create subsets for each user\n",
    "    user_datasets = [torch.utils.data.Subset(combined_dataset, user_data[i]) for i in range(N)]\n",
    "    \n",
    "    return user_datasets\n",
    "\n",
    "\n",
    "def split_train_test(user_dataset, test_ratio=0.2):\n",
    "    # Total number of samples\n",
    "    M = len(user_dataset)\n",
    "    test_size = int(M * test_ratio)\n",
    "    train_size = M - test_size\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    train_subset, test_subset = random_split(user_dataset, [train_size, test_size])\n",
    "    \n",
    "    return train_subset, test_subset\n",
    "\n",
    "\n",
    "user_datasets = split_dataset(combined_dataset, N)\n",
    "\n",
    "batch_size = 64  # Adjust batch size as needed\n",
    "\n",
    "# Split user-specific dataset into training and testing sets\n",
    "user_train_loaders = []\n",
    "user_test_loaders = []\n",
    "for user_dataset in user_datasets:\n",
    "    train_data, test_data = split_train_test(user_dataset)\n",
    "    user_train_loaders.append(DataLoader(train_data, batch_size=batch_size, shuffle=True))\n",
    "    user_test_loaders.append(DataLoader(test_data, batch_size=batch_size, shuffle=False))\n",
    "    \n",
    "def aggregate_updates(local_updates):\n",
    "    # A naive method to aggregate model weights\n",
    "    new_state_dict = {}\n",
    "    for key in local_updates[0].keys():\n",
    "        new_state_dict[key] = torch.mean(torch.stack([update[key] for update in local_updates]), dim=0)\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2247ae28-7a7e-49f3-9cb4-71759ad5f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = x.reshape(-1, 64 * 7 * 7)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8642f7-7f5f-40cd-9e37-9783deeab44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aghalkha21\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "global_model = Net().to(device)\n",
    "\n",
    "client_models = [Net().to(device) for i in range(N)]\n",
    "\n",
    "for model in client_models + [global_model]:\n",
    "    # Fuse layers (for better optimization during quantization)\n",
    "    model.fuse_model = lambda: torch.quantization.fuse_modules(model, [[\"conv1\", \"relu1\"], [\"conv2\", \"relu2\"]])\n",
    "    model.fuse_model()\n",
    "    \n",
    "    # Specify quantization configuration\n",
    "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "    \n",
    "    # Prepare for QAT\n",
    "    model = torch.quantization.prepare_qat(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de2ebb7c-f510-4759-a436-bd75914db580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_models[0].load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e063b09-66c3-4c2f-b2b5-3f2378b293a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 - Epoch 1/10 - Test Accuracy: 25.71%\n",
      "User 2 - Epoch 1/10 - Test Accuracy: 28.71%\n",
      "User 3 - Epoch 1/10 - Test Accuracy: 12.71%\n",
      "User 4 - Epoch 1/10 - Test Accuracy: 9.86%\n",
      "User 5 - Epoch 1/10 - Test Accuracy: 23.29%\n",
      "User 6 - Epoch 1/10 - Test Accuracy: 15.00%\n",
      "User 7 - Epoch 1/10 - Test Accuracy: 15.71%\n",
      "User 8 - Epoch 1/10 - Test Accuracy: 20.86%\n",
      "User 9 - Epoch 1/10 - Test Accuracy: 19.29%\n",
      "User 10 - Epoch 1/10 - Test Accuracy: 17.57%\n",
      "User 11 - Epoch 1/10 - Test Accuracy: 26.14%\n",
      "User 12 - Epoch 1/10 - Test Accuracy: 14.29%\n",
      "User 13 - Epoch 1/10 - Test Accuracy: 10.71%\n",
      "User 14 - Epoch 1/10 - Test Accuracy: 10.86%\n",
      "User 15 - Epoch 1/10 - Test Accuracy: 30.00%\n",
      "User 16 - Epoch 1/10 - Test Accuracy: 17.86%\n",
      "User 17 - Epoch 1/10 - Test Accuracy: 21.57%\n",
      "User 18 - Epoch 1/10 - Test Accuracy: 34.57%\n",
      "User 19 - Epoch 1/10 - Test Accuracy: 26.71%\n",
      "User 20 - Epoch 1/10 - Test Accuracy: 21.57%\n",
      "Epoch 1/10 completed.\n",
      "User 1 - Epoch 2/10 - Test Accuracy: 56.00%\n",
      "User 2 - Epoch 2/10 - Test Accuracy: 39.00%\n",
      "User 3 - Epoch 2/10 - Test Accuracy: 32.43%\n",
      "User 4 - Epoch 2/10 - Test Accuracy: 34.43%\n",
      "User 5 - Epoch 2/10 - Test Accuracy: 47.57%\n",
      "User 6 - Epoch 2/10 - Test Accuracy: 40.57%\n",
      "User 7 - Epoch 2/10 - Test Accuracy: 38.29%\n",
      "User 8 - Epoch 2/10 - Test Accuracy: 50.00%\n",
      "User 9 - Epoch 2/10 - Test Accuracy: 47.86%\n",
      "User 10 - Epoch 2/10 - Test Accuracy: 39.00%\n",
      "User 11 - Epoch 2/10 - Test Accuracy: 50.29%\n",
      "User 12 - Epoch 2/10 - Test Accuracy: 33.43%\n",
      "User 13 - Epoch 2/10 - Test Accuracy: 53.14%\n",
      "User 14 - Epoch 2/10 - Test Accuracy: 36.14%\n",
      "User 15 - Epoch 2/10 - Test Accuracy: 48.57%\n",
      "User 16 - Epoch 2/10 - Test Accuracy: 38.29%\n",
      "User 17 - Epoch 2/10 - Test Accuracy: 36.86%\n",
      "User 18 - Epoch 2/10 - Test Accuracy: 56.71%\n",
      "User 19 - Epoch 2/10 - Test Accuracy: 34.43%\n",
      "User 20 - Epoch 2/10 - Test Accuracy: 43.71%\n",
      "Epoch 2/10 completed.\n",
      "User 1 - Epoch 3/10 - Test Accuracy: 66.86%\n",
      "User 2 - Epoch 3/10 - Test Accuracy: 61.57%\n",
      "User 3 - Epoch 3/10 - Test Accuracy: 54.57%\n",
      "User 4 - Epoch 3/10 - Test Accuracy: 50.86%\n",
      "User 5 - Epoch 3/10 - Test Accuracy: 57.43%\n",
      "User 6 - Epoch 3/10 - Test Accuracy: 60.71%\n",
      "User 7 - Epoch 3/10 - Test Accuracy: 56.71%\n",
      "User 8 - Epoch 3/10 - Test Accuracy: 59.29%\n",
      "User 9 - Epoch 3/10 - Test Accuracy: 56.14%\n",
      "User 10 - Epoch 3/10 - Test Accuracy: 61.43%\n",
      "User 11 - Epoch 3/10 - Test Accuracy: 56.57%\n",
      "User 12 - Epoch 3/10 - Test Accuracy: 63.43%\n",
      "User 13 - Epoch 3/10 - Test Accuracy: 69.57%\n",
      "User 14 - Epoch 3/10 - Test Accuracy: 66.00%\n",
      "User 15 - Epoch 3/10 - Test Accuracy: 52.14%\n",
      "User 16 - Epoch 3/10 - Test Accuracy: 65.00%\n",
      "User 17 - Epoch 3/10 - Test Accuracy: 58.29%\n",
      "User 18 - Epoch 3/10 - Test Accuracy: 63.14%\n",
      "User 19 - Epoch 3/10 - Test Accuracy: 59.14%\n",
      "User 20 - Epoch 3/10 - Test Accuracy: 61.57%\n",
      "Epoch 3/10 completed.\n",
      "User 1 - Epoch 4/10 - Test Accuracy: 71.43%\n",
      "User 2 - Epoch 4/10 - Test Accuracy: 71.29%\n",
      "User 3 - Epoch 4/10 - Test Accuracy: 67.71%\n",
      "User 4 - Epoch 4/10 - Test Accuracy: 63.43%\n",
      "User 5 - Epoch 4/10 - Test Accuracy: 72.43%\n",
      "User 6 - Epoch 4/10 - Test Accuracy: 64.14%\n",
      "User 7 - Epoch 4/10 - Test Accuracy: 69.86%\n",
      "User 8 - Epoch 4/10 - Test Accuracy: 65.00%\n",
      "User 9 - Epoch 4/10 - Test Accuracy: 70.43%\n",
      "User 10 - Epoch 4/10 - Test Accuracy: 66.57%\n",
      "User 11 - Epoch 4/10 - Test Accuracy: 70.29%\n",
      "User 12 - Epoch 4/10 - Test Accuracy: 58.29%\n",
      "User 13 - Epoch 4/10 - Test Accuracy: 73.71%\n",
      "User 14 - Epoch 4/10 - Test Accuracy: 68.00%\n",
      "User 15 - Epoch 4/10 - Test Accuracy: 68.14%\n",
      "User 16 - Epoch 4/10 - Test Accuracy: 71.57%\n",
      "User 17 - Epoch 4/10 - Test Accuracy: 68.43%\n",
      "User 18 - Epoch 4/10 - Test Accuracy: 73.86%\n",
      "User 19 - Epoch 4/10 - Test Accuracy: 69.14%\n",
      "User 20 - Epoch 4/10 - Test Accuracy: 68.71%\n",
      "Epoch 4/10 completed.\n",
      "User 1 - Epoch 5/10 - Test Accuracy: 75.43%\n",
      "User 2 - Epoch 5/10 - Test Accuracy: 76.71%\n",
      "User 3 - Epoch 5/10 - Test Accuracy: 69.43%\n",
      "User 4 - Epoch 5/10 - Test Accuracy: 70.86%\n",
      "User 5 - Epoch 5/10 - Test Accuracy: 76.43%\n",
      "User 6 - Epoch 5/10 - Test Accuracy: 75.71%\n",
      "User 7 - Epoch 5/10 - Test Accuracy: 70.86%\n",
      "User 8 - Epoch 5/10 - Test Accuracy: 68.86%\n",
      "User 9 - Epoch 5/10 - Test Accuracy: 75.86%\n",
      "User 10 - Epoch 5/10 - Test Accuracy: 68.14%\n",
      "User 11 - Epoch 5/10 - Test Accuracy: 74.29%\n",
      "User 12 - Epoch 5/10 - Test Accuracy: 72.29%\n",
      "User 13 - Epoch 5/10 - Test Accuracy: 74.57%\n",
      "User 14 - Epoch 5/10 - Test Accuracy: 75.29%\n",
      "User 15 - Epoch 5/10 - Test Accuracy: 73.71%\n",
      "User 16 - Epoch 5/10 - Test Accuracy: 74.29%\n",
      "User 17 - Epoch 5/10 - Test Accuracy: 77.29%\n",
      "User 18 - Epoch 5/10 - Test Accuracy: 71.57%\n",
      "User 19 - Epoch 5/10 - Test Accuracy: 73.71%\n",
      "User 20 - Epoch 5/10 - Test Accuracy: 70.14%\n",
      "Epoch 5/10 completed.\n",
      "User 1 - Epoch 6/10 - Test Accuracy: 76.29%\n",
      "User 2 - Epoch 6/10 - Test Accuracy: 77.14%\n",
      "User 3 - Epoch 6/10 - Test Accuracy: 76.14%\n",
      "User 4 - Epoch 6/10 - Test Accuracy: 75.14%\n",
      "User 5 - Epoch 6/10 - Test Accuracy: 77.00%\n",
      "User 6 - Epoch 6/10 - Test Accuracy: 77.86%\n",
      "User 7 - Epoch 6/10 - Test Accuracy: 77.00%\n",
      "User 8 - Epoch 6/10 - Test Accuracy: 71.71%\n",
      "User 9 - Epoch 6/10 - Test Accuracy: 80.57%\n",
      "User 10 - Epoch 6/10 - Test Accuracy: 75.43%\n",
      "User 11 - Epoch 6/10 - Test Accuracy: 78.00%\n",
      "User 12 - Epoch 6/10 - Test Accuracy: 77.29%\n",
      "User 13 - Epoch 6/10 - Test Accuracy: 77.86%\n",
      "User 14 - Epoch 6/10 - Test Accuracy: 75.00%\n",
      "User 15 - Epoch 6/10 - Test Accuracy: 78.71%\n",
      "User 16 - Epoch 6/10 - Test Accuracy: 79.86%\n",
      "User 17 - Epoch 6/10 - Test Accuracy: 74.57%\n",
      "User 18 - Epoch 6/10 - Test Accuracy: 74.43%\n",
      "User 19 - Epoch 6/10 - Test Accuracy: 77.86%\n",
      "User 20 - Epoch 6/10 - Test Accuracy: 75.00%\n",
      "Epoch 6/10 completed.\n",
      "User 1 - Epoch 7/10 - Test Accuracy: 81.86%\n",
      "User 2 - Epoch 7/10 - Test Accuracy: 81.57%\n",
      "User 3 - Epoch 7/10 - Test Accuracy: 80.29%\n",
      "User 4 - Epoch 7/10 - Test Accuracy: 78.43%\n",
      "User 5 - Epoch 7/10 - Test Accuracy: 79.71%\n",
      "User 6 - Epoch 7/10 - Test Accuracy: 80.86%\n",
      "User 7 - Epoch 7/10 - Test Accuracy: 80.00%\n",
      "User 8 - Epoch 7/10 - Test Accuracy: 74.71%\n",
      "User 9 - Epoch 7/10 - Test Accuracy: 80.14%\n",
      "User 10 - Epoch 7/10 - Test Accuracy: 79.29%\n",
      "User 11 - Epoch 7/10 - Test Accuracy: 82.14%\n",
      "User 12 - Epoch 7/10 - Test Accuracy: 80.14%\n",
      "User 13 - Epoch 7/10 - Test Accuracy: 80.14%\n",
      "User 14 - Epoch 7/10 - Test Accuracy: 84.14%\n",
      "User 15 - Epoch 7/10 - Test Accuracy: 81.71%\n",
      "User 16 - Epoch 7/10 - Test Accuracy: 83.00%\n",
      "User 17 - Epoch 7/10 - Test Accuracy: 81.57%\n",
      "User 18 - Epoch 7/10 - Test Accuracy: 81.00%\n",
      "User 19 - Epoch 7/10 - Test Accuracy: 78.71%\n",
      "User 20 - Epoch 7/10 - Test Accuracy: 79.43%\n",
      "Epoch 7/10 completed.\n",
      "User 1 - Epoch 8/10 - Test Accuracy: 83.14%\n",
      "User 2 - Epoch 8/10 - Test Accuracy: 82.14%\n",
      "User 3 - Epoch 8/10 - Test Accuracy: 80.57%\n",
      "User 4 - Epoch 8/10 - Test Accuracy: 82.29%\n",
      "User 5 - Epoch 8/10 - Test Accuracy: 83.71%\n",
      "User 6 - Epoch 8/10 - Test Accuracy: 82.86%\n",
      "User 7 - Epoch 8/10 - Test Accuracy: 83.14%\n",
      "User 8 - Epoch 8/10 - Test Accuracy: 81.71%\n",
      "User 9 - Epoch 8/10 - Test Accuracy: 83.00%\n",
      "User 10 - Epoch 8/10 - Test Accuracy: 82.00%\n",
      "User 11 - Epoch 8/10 - Test Accuracy: 83.00%\n",
      "User 12 - Epoch 8/10 - Test Accuracy: 81.57%\n",
      "User 13 - Epoch 8/10 - Test Accuracy: 82.29%\n",
      "User 14 - Epoch 8/10 - Test Accuracy: 85.29%\n",
      "User 15 - Epoch 8/10 - Test Accuracy: 82.29%\n",
      "User 16 - Epoch 8/10 - Test Accuracy: 84.14%\n",
      "User 17 - Epoch 8/10 - Test Accuracy: 85.14%\n",
      "User 18 - Epoch 8/10 - Test Accuracy: 84.29%\n",
      "User 19 - Epoch 8/10 - Test Accuracy: 83.86%\n",
      "User 20 - Epoch 8/10 - Test Accuracy: 79.57%\n",
      "Epoch 8/10 completed.\n",
      "User 1 - Epoch 9/10 - Test Accuracy: 85.00%\n",
      "User 2 - Epoch 9/10 - Test Accuracy: 82.43%\n",
      "User 3 - Epoch 9/10 - Test Accuracy: 80.00%\n",
      "User 4 - Epoch 9/10 - Test Accuracy: 83.00%\n",
      "User 5 - Epoch 9/10 - Test Accuracy: 86.00%\n",
      "User 6 - Epoch 9/10 - Test Accuracy: 85.29%\n",
      "User 7 - Epoch 9/10 - Test Accuracy: 84.57%\n",
      "User 8 - Epoch 9/10 - Test Accuracy: 82.43%\n",
      "User 9 - Epoch 9/10 - Test Accuracy: 83.71%\n",
      "User 10 - Epoch 9/10 - Test Accuracy: 81.14%\n",
      "User 11 - Epoch 9/10 - Test Accuracy: 82.43%\n",
      "User 12 - Epoch 9/10 - Test Accuracy: 84.14%\n",
      "User 13 - Epoch 9/10 - Test Accuracy: 85.00%\n",
      "User 14 - Epoch 9/10 - Test Accuracy: 85.14%\n",
      "User 15 - Epoch 9/10 - Test Accuracy: 86.71%\n",
      "User 16 - Epoch 9/10 - Test Accuracy: 84.29%\n",
      "User 17 - Epoch 9/10 - Test Accuracy: 86.43%\n",
      "User 18 - Epoch 9/10 - Test Accuracy: 85.71%\n",
      "User 19 - Epoch 9/10 - Test Accuracy: 84.00%\n",
      "User 20 - Epoch 9/10 - Test Accuracy: 83.00%\n",
      "Epoch 9/10 completed.\n",
      "User 1 - Epoch 10/10 - Test Accuracy: 85.29%\n",
      "User 2 - Epoch 10/10 - Test Accuracy: 86.43%\n",
      "User 3 - Epoch 10/10 - Test Accuracy: 85.43%\n",
      "User 4 - Epoch 10/10 - Test Accuracy: 85.57%\n",
      "User 5 - Epoch 10/10 - Test Accuracy: 87.57%\n",
      "User 6 - Epoch 10/10 - Test Accuracy: 84.14%\n",
      "User 7 - Epoch 10/10 - Test Accuracy: 87.29%\n",
      "User 8 - Epoch 10/10 - Test Accuracy: 84.71%\n",
      "User 9 - Epoch 10/10 - Test Accuracy: 84.71%\n",
      "User 10 - Epoch 10/10 - Test Accuracy: 86.43%\n",
      "User 11 - Epoch 10/10 - Test Accuracy: 83.00%\n",
      "User 12 - Epoch 10/10 - Test Accuracy: 84.14%\n",
      "User 13 - Epoch 10/10 - Test Accuracy: 87.00%\n",
      "User 14 - Epoch 10/10 - Test Accuracy: 87.00%\n",
      "User 15 - Epoch 10/10 - Test Accuracy: 87.00%\n",
      "User 16 - Epoch 10/10 - Test Accuracy: 86.86%\n",
      "User 17 - Epoch 10/10 - Test Accuracy: 88.14%\n",
      "User 18 - Epoch 10/10 - Test Accuracy: 87.71%\n",
      "User 19 - Epoch 10/10 - Test Accuracy: 87.14%\n",
      "User 20 - Epoch 10/10 - Test Accuracy: 84.57%\n",
      "Epoch 10/10 completed.\n"
     ]
    }
   ],
   "source": [
    "avg_test_accs = []\n",
    "def federated_train(global_model, client_models, user_train_loaders, user_test_loaders, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        local_updates = []\n",
    "        test_accs = []\n",
    "        for i in range(N):\n",
    "            # Copy the global model for each user\n",
    "            client_models[i].load_state_dict(global_model.state_dict())\n",
    "            optimizer = torch.optim.SGD(client_models[i].parameters(), lr=0.01)  # Example with SGD optimizer\n",
    "\n",
    "            \n",
    "            # Train the local model on the user's training data\n",
    "            for data, target in user_train_loaders[i]:\n",
    "                optimizer.zero_grad()\n",
    "                output = client_models[i](data)\n",
    "                loss = torch.nn.functional.cross_entropy(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Save the local model state dict\n",
    "            local_updates.append(client_models[i].state_dict())\n",
    "            \n",
    "            # Evaluate on the test set of the user\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in user_test_loaders[i]:\n",
    "                    output = client_models[i](data)\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    total += target.size(0)\n",
    "                    correct += (predicted == target).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "            print(f\"User {i+1} - Epoch {epoch+1}/{epochs} - Test Accuracy: {accuracy:.2f}%\")\n",
    "            test_accs.append(accuracy)\n",
    "        \n",
    "        # Aggregate updates from all users\n",
    "        aggregated_model_state = aggregate_updates(local_updates)\n",
    "        global_model.load_state_dict(aggregated_model_state)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed.\")\n",
    "        avg_test_accs.append(sum(test_accs) / len(test_accs))\n",
    "\n",
    "# Example usage\n",
    "#global_model = Net().to(device)\n",
    "federated_train(global_model, client_models, user_train_loaders, user_test_loaders, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adde05-747a-4dbc-91a6-f15280b50cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quantized = torch.quantization.convert(model_prepared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1b000-26fa-4519-ad79-7d9cae8e202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate quantized model\n",
    "model_quantized.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_quantized(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the quantized model on the test set: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35ff4e-7b57-4d24-86f1-c721ae9e51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in model_quantized.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04cf58-c409-49ef-81f2-12bfe3992850",
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.numel() for p in model_prepared.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576cf5a-2588-4d3c-bf1c-916fb8ba912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58e76f-ae8b-4b02-957a-c4655d07dc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
